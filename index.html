<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="FloatWaste: A Multi-Regional Floating Debris Detection Dataset for Smart Cities">
  <meta name="language" content="English">


  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>FloatWaste: A Multi-Regional Floating Debris Detection Dataset for Smart Cities</title>


  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>

</head>

<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <!-- TODO: Replace with your paper title -->
              <h1 class="title is-1 publication-title">FloatWaste: A Multi-Regional Floating Debris Detection Dataset
                for Smart Cities
              </h1>

              <div class="is-size-4 publication-authors is-flex is-justify-content-center">
                <div class="author-block is-flex is-align-items-center">
                  <img src="static/images/logo.jpg" alt="CSIRO Logo" class="institution-logo mr-2" />
                  <span>CSIRO Team (Hobart)</span>
                </div>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- TODO: Update with your arXiv paper ID -->
                  <span class="link-block">
                    <a href="." target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>

                  <!-- TODO: Add your supplementary material PDF or remove this section -->
                  <span class="link-block">
                    <a href="." target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon" style="vertical-align: middle; font-size: 20px;">ðŸ¤—</span>
                      <span style="vertical-align: middle;">Dataset</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="." target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- TODO: Update with your arXiv paper ID -->
                  <span class="link-block">
                    <a href="." target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon" style="vertical-align: middle; font-size: 20px;">ðŸ¤—</span>
                      <span style="vertical-align: middle;">Demo</span>
                    </a>
                  </span>
                </div>

              </div>
            </div>
          </div>
        </div>
    </section>


    <!-- Dataset Overview -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <!-- <h2 class="title is-3">Dataset Overview</h2> -->
          <div class="columns is-centered has-text-centered has-text-justified">
            <div class="column is-four-fifths">
              <p>
                <img src="./static/images/banner.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                <img src="./static/images/do.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                Our aquatic litter dataset consists of a total of 7,906 images collected from three distinct
                geographical regions, covering 25 litter categories and 11 different litter materials. All images are
                manually annotated, resulting in 27,583 bounding boxes in total.
                Figures present detailed statistical analyses of the dataset: (a) the distribution of images across
                different regions; (b) the histogram of the number of bounding boxes per image; (c) the distribution of
                bounding boxes across different litter categories; (d) the distribution of bounding boxes among
                different litter materials; and (e) the distribution of images for each litter category under different
                litter materials.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Dataset Overview -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <!-- TODO: Replace with your paper abstract -->
              <p>
                Plastic pollution in oceans poses substantial threats to human health, economic development, and marine
                biodiversity, with rivers serving as the principal transport pathway for inland waste. While
                camera-based AI monitoring offers a scalable alternative to labor-intensive manual surveys, existing
                computer vision datasets fail to capture the complex visual conditions of real-world riverine
                environments leaving floating waste detection critically underexplored. To rectify this, we introduce
                FloatWaste, the first comprehensive, multi-region dataset for floating riverine waste detection,
                comprising 27,583 expert-annotated bounding boxes across 25 fine-grained waste categories spanning 11
                material types, collected from diverse aquatic settings worldwide. Each annotation was validated through
                cross-verification by environmental scientists and local domain experts to ensure label accuracy.
                Extensive evaluation of representative vision models reveals critical challenges: detecting small and
                partially submerged objects under glare and clutter, maintaining robust performance under cross-domain
                distribution shifts, handling severe occlusion and other complexities. Beyond advancing computer vision
                research, FloatWaste directly enables real-world applications including automated upstream waste
                interception systems and waterway cleanliness monitoring, facilitating effective waste management before
                debris reaches the ocean.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Cameras installation -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3">Cameras installation</h2>
          <div class="columns is-centered has-text-justified">
            <div class="column is-four-fifths">
              <p>
                <img src="./static/images/ci.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                The map of the camera's placement distribution for Phase 1 monitoring activity, illustrating the
                river's length from block A to block B, which is approximately 6.3 km. This visual representation helps
                to
                understand the extensive coverage of the monitoring system along the river, ensuring that each section
                is adequately observed and managed.Block A is situated in the eastern part of Bandung, specifically
                around the Citarik River. Six cameras
                were installed, positioned at the lower reaches of the Cikijing River (Cam-1), the Cimande River
                (Cam-2), the Citarik River(Cam 3), and at the confluence of the Cimande and Cikijing (Cam-4), and
                lastly the confluence of Citarik, Cimande, Cikijing Rivers (Cam-Opt & Cam-5). Block B covers the
                Citarik, the main Citarum River, and the Cikeruh River. Four cameras were installed
                in Sapan, located in the central basin of Bandung, specifically at the lower reaches of the Citarik
                (Cam-6 & Cam-7), the main Citarum (Cam-8), and the Cikeruh (Cam-9).

              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Cameras installation -->

    <!-- Detection -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3">Detection</h2>
          <div class="columns is-centered has-text-justified">
            <div class="column is-four-fifths">
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item item-video1">
                  <!-- TODO: Add poster image for better preview -->
                  <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
                    <!-- Your video file here -->
                    <source src="static/videos/HalfRes_25_0.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="item item-video2">
                  <!-- TODO: Add poster image for better preview -->
                  <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
                    <!-- Your video file here -->
                    <source src="static/videos/HalfRes_25_7.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="item item-video3">
                  <!-- TODO: Add poster image for better preview -->
                  <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
                    <!-- Your video file here -->
                    <source src="static/videos/HalfRes_28_0.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="item item-video3">
                  <!-- TODO: Add poster image for better preview -->
                  <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
                    <!-- Your video file here -->
                    <source src="static/videos/HalfRes_29_1.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
              <br></br>

              <h2 class="title is-5 has-text-centered">Challenge 1 : Small Objects</h2>
              <p>
                <img src="./static/images/xmb.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                A major challenge in floating litter detection lies in the prevalence of extremely small objects. Many
                debris instances occupy only a tiny fraction of the image, often suffering from low resolution, motion
                blur, and background clutter caused by water reflections and waves. Such small-scale targets provide
                very limited visual cues, making them difficult to distinguish even for state-of-the-art large
                vision-language models. In practice, we observe that powerful models such as InternVL2.5-13B still
                struggle to reliably perceive and localize these small litter instances, frequently missing them or
                confusing them with background noise. This highlights the fundamental difficulty of small-object
                perception in real-world marine environments.
              </p>
              <br></br>

              <h2 class="title is-5 has-text-centered">Challenge 2 : Dense Object</h2>
              <p>
                <img src="./static/images/cmmb.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                Beyond small objects, highly dense litter distributions pose another critical challenge for garbage
                detection. In real-world water surfaces, a large number of debris instances often appear in close
                proximity, leading to severe occlusion, overlapping boundaries, and indistinguishable visual cues. Such
                dense scenes substantially degrade detection performance. Our empirical observations show that even
                strong detectors and visionâ€“language models, including DINO, InternVL2.5, and Qwen2.5VL-72B, struggle to
                handle these scenarios effectively, suffering from frequent false positives and missed detections under
                high-density conditions.
              </p>
              <br></br>

              <h2 class="title is-5 has-text-centered">Challenge 3 : Specular Reflection</h2>
              <p>
                <img src="./static/images/sfg.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                In aquatic environments, strong surface reflections introduce severe visual interference for garbage
                detection. Specular highlights and mirror-like reflections distort object appearance, obscure true
                boundaries, and confuse spatial cues, making it difficult for models to accurately localize debris. More
                critically, reflections of surrounding objects are often mistakenly recognized as litter, leading to
                false detections. This reflection-induced ambiguity significantly degrades detection robustness and
                poses a major challenge for reliable real-world deployment.
              </p>
              <br></br>

              <h2 class="title is-5 has-text-centered">Challenge 4 : Blurred Objects</h2>
              <p>
                <img src="./static/images/mhmb.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                Blurred garbage objects pose a significant challenge to reliable detection. Due to motion blur, defocus,
                or low image quality, garbage instances often lack clear visual cues, which can easily mislead detection
                models into classifying them as background or failing to perceive their presence altogether. This
                ambiguity substantially increases the risk of missed detections and false predictions, thereby degrading
                the robustness of garbage detection systems.
              </p>
              <br></br>

              <h2 class="title is-5 has-text-centered">Challenge 5 : Background Interference</h2>
              <p>
                <img src="./static/images/yhx.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                Background clutter and visual similarity between garbage and its surrounding environment pose
                significant challenges to accurate detection. In particular, when garbage objects share similar color,
                texture, or appearance with the background (e.g., garbage floating on water surfaces), detection models
                are easily confused and tend to misclassify garbage as background. Even powerful foundation models such
                as DINO and Florence struggle to reliably distinguish garbage targets under such high backgroundâ€“object
                similarity, leading to increased false negatives and degraded detection performance.
              </p>
              <br></br>

              <h2 class="title is-5 has-text-centered">Challenge 6 : Geographical Diversity</h2>
              <p>
                <img src="./static/images/sdq.png" alt="Directional Weight Score"
                  class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy">
              </p>
              <p>
                Geographical diversity introduces substantial variability in garbage detection. Our dataset spans three
                distinct regionsâ€”Hobart, New South Wales, and Indonesiaâ€”where garbage types, appearance, and spatial
                distributions differ significantly. Such cross-region heterogeneity poses higher demands on model
                robustness and generalization, as detection models must adapt to diverse environmental conditions and
                unseen regional characteristics.
              </p>
              <br></br>

            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Detection -->



    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>